{"Modified": "2016-08-05T16:59:20.370-04:00", "vulnerable_configuration": [{"title": "Google Android 6.0", "id": "cpe:2.3:o:google:android:6.0"}, {"title": "Google Android 6.0.1", "id": "cpe:2.3:o:google:android:6.0.1"}], "vulnerable_configuration_cpe_2_2": ["cpe:/o:google:android:6.0", "cpe:/o:google:android:6.0.1"], "last-modified": "2016-11-28T15:12:30.017-05:00", "references": ["http://source.android.com/security/bulletin/2016-08-01.html", "http://www.securityfocus.com/bid/92221", "https://android.googlesource.com/platform/external/libavc/+/326fe991a4b7971e8aeaf4ac775491dd8abd85bb"], "ranking": [[{"circl": 2}]], "cwe": "CWE-172", "cvss": "7.1", "capec": [{"related_weakness": ["173", "172", "180", "181", "171", "73", "21", "74", "20", "697", "692"], "solutions": ["Assume all input might use an improper representation. Use canonicalized data inside the application; all data must be converted into the representation used inside the application (UTF-8, UTF-16, etc.)", "Assume all input is malicious. Create a white list that defines all valid input to the software system based on the requirements specifications. Input that does not match against the white list should not be permitted to enter into the system. Test your decoding process against malicious input."], "id": "267", "prerequisites": ["The application's decoder accepts and interprets encoded characters. Data canonicalization, input filtering and validating is not done properly leaving the door open to harmful characters for the target host."], "summary": ["This attack leverages the possibility to encode potentially harmful input and submit it to applications not expecting or effective at validating this encoding standard making input filtering difficult."], "name": "Leverage Alternate Encoding"}, {"related_weakness": ["173", "41", "172", "171", "179", "180", "181", "183", "184", "20", "74", "697", "707"], "solutions": ["Perform white list rather than black list input validation.", "Canonicalize all data prior to validation.", "Take an iterative approach to input validation (defense in depth)."], "id": "3", "prerequisites": ["The targeted API must ignore the leading ghost characters that are used to get past the filters for the semantics to be the same."], "summary": ["An attacker intentionally introduces leading characters that enable getting the input past the filters. The API that is being targeted, ignores the leading \"ghost\" characters, and therefore processes the attackers' input. This occurs when the targeted API will accept input data in several syntactic forms and interpret it in the equivalent semantic way, while the filter does not take into account the full spectrum of the syntactic forms acceptable to the targeted API.", "Some APIs will strip certain leading characters from a string of parameters. Perhaps these characters are considered redundant, and for this reason they are removed. Another possibility is the parser logic at the beginning of analysis is specialized in some way that causes some characters to be removed. The attacker can specify multiple types of alternative encodings at the beginning of a string as a set of probes.", "One commonly used possibility involves adding ghost characters--extra characters that don't affect the validity of the request at the API layer. If the attacker has access to the API libraries being targeted, certain attack ideas can be tested directly in advance. Once alternative ghost encodings emerge through testing, the attacker can move from lab-based API testing to testing real-world service implementations."], "name": "Using Leading 'Ghost' Character Sequences to Bypass Input Filters"}, {"related_weakness": ["158", "172", "173", "171", "74", "20", "697", "707"], "solutions": ["Properly handle the NULL characters supplied as part of user input prior to doing anything with the data."], "id": "52", "prerequisites": ["The program does not properly handle postfix NULL terminators"], "summary": ["An attacker embeds one or more null bytes in input to the target software. This attack relies on the usage of a null-valued byte as a string terminator in many environments. The goal is for certain components of the target software to stop processing the input when it encounters the null byte(s)."], "name": "Embedding NULL Bytes"}, {"related_weakness": ["158", "172", "173", "171", "74", "20", "697", "707"], "solutions": ["Properly handle Null characters. Make sure canonicalization is properly applied. Do not pass Null characters to the underlying APIs.", "Assume all input is malicious. Create a white list that defines all valid input to the software system based on the requirements specifications. Input that does not match against the white list should not be permitted to enter into the system."], "id": "53", "prerequisites": ["Null terminators are not properly handled by the filter."], "summary": ["If a string is passed through a filter of some kind, then a terminal NULL may not be valid. Using alternate representation of NULL allows an attacker to embed the NULL mid-string while postfixing the proper data so that the filter is avoided. One example is a filter that looks for a trailing slash character. If a string insertion is possible, but the slash must exist, an alternate encoding of NULL in mid-string may be used."], "name": "Postfix, Null Terminate, and Backslash"}, {"related_weakness": ["177", "171", "173", "172", "73", "21", "22", "74", "20", "697", "707"], "solutions": ["Assume all input is malicious. Create a white list that defines all valid input to the software system based on the requirements specifications. Input that does not match against the white list should not be permitted to enter into the system. Test your decoding process against malicious input.", "Be aware of the threat of alternative method of data encoding and obfuscation technique such as IP address encoding.", "When client input is required from web-based forms, avoid using the \"GET\" method to submit data, as the method causes the form data to be appended to the URL and is easily manipulated. Instead, use the \"POST method whenever possible.", "Any security checks should occur after the data has been decoded and validated as correct data format. Do not repeat decoding process, if bad character are left after decoding process, treat the data as suspicious, and fail the validation process.", "Refer to the RFCs to safely decode URL.", "Regular expression can be used to match safe URL patterns. However, that may discard valid URL requests if the regular expression is too restrictive.", "There are tools to scan HTTP requests to the server for valid URL such as URLScan from Microsoft (http://www.microsoft.com/technet/security/tools/urlscan.mspx)."], "id": "64", "prerequisites": ["The application accepts and decodes URL string request.", "The application performs insufficient filtering/canonicalization on the URLs."], "summary": ["This attack targets the encoding of the URL combined with the encoding of the slash characters. An attacker can take advantage of the multiple way of encoding an URL and abuse the interpretation of the URL. An URL may contain special character that need special syntax handling in order to be interpreted. Special characters are represented using a percentage character followed by two digits representing the octet code of the original character (%HEX-CODE). For instance US-ASCII space character would be represented with %20. This is often referred as escaped ending or percent-encoding. Since the server decodes the URL from the requests, it may restrict the access to some URL paths by validating and filtering out the URL requests it received. An attacker will try to craft an URL with a sequence of special characters which once interpreted by the server will be equivalent to a forbidden URL. It can be difficult to protect against this attack since the URL can contain other format of encoding such as UTF-8 encoding, Unicode-encoding, etc."], "name": "Using Slashes and URL Encoding Combined to Bypass Validation Logic"}, {"related_weakness": ["176", "171", "179", "180", "173", "172", "184", "183", "74", "20", "697", "692"], "solutions": ["Ensure that the system is Unicode aware and can properly process Unicode data. Do not make an assumption that data will be in ASCII.", "Ensure that filtering or input validation is applied to canonical data.", "Assume all input is malicious. Create a white list that defines all valid input to the software system based on the requirements specifications. Input that does not match against the white list should not be permitted to enter into the system."], "id": "71", "prerequisites": ["Filtering is performed on data that has not be properly canonicalized."], "summary": ["An attacker may provide a Unicode string to a system component that is not Unicode aware and use that to circumvent the filter or cause the classifying mechanism to fail to properly understanding the request. That may allow the attacker to slip malicious data past the content filter and/or possibly cause the application to route the request incorrectly."], "name": "Using Unicode Encoding to Bypass Validation Logic"}, {"related_weakness": ["173", "177", "171", "172", "73", "21", "74", "20"], "solutions": ["Refer to the RFCs to safely decode URL.", "Regular expression can be used to match safe URL patterns. However, that may discard valid URL requests if the regular expression is too restrictive.", "There are tools to scan HTTP requests to the server for valid URL such as URLScan from Microsoft (http://www.microsoft.com/technet/security/tools/urlscan.mspx).", "Any security checks should occur after the data has been decoded and validated as correct data format. Do not repeat decoding process, if bad character are left after decoding process, treat the data as suspicious, and fail the validation process.", "Assume all input is malicious. Create a white list that defines all valid input to the software system based on the requirements specifications. Input that does not match against the white list should not be permitted to enter into the system. Test your decoding process against malicious input.", "Be aware of the threat of alternative method of data encoding and obfuscation technique such as IP address encoding. (See related guideline section)", "When client input is required from web-based forms, avoid using the \"GET\" method to submit data, as the method causes the form data to be appended to the URL and is easily manipulated. Instead, use the \"POST method whenever possible."], "id": "72", "prerequisites": ["The application should accepts and decodes URL input.", "The application performs insufficient filtering/canonicalization on the URLs."], "summary": ["This attack targets the encoding of the URL. An attacker can take advantage of the multiple way of encoding an URL and abuse the interpretation of the URL. An URL may contain special character that need special syntax handling in order to be interpreted. Special characters are represented using a percentage character followed by two digits representing the octet code of the original character (%HEX-CODE). For instance US-ASCII space character would be represented with %20. This is often referred as escaped ending or percent-encoding. Since the server decodes the URL from the requests, it may restrict the access to some URL paths by validating and filtering out the URL requests it received. An attacker will try to craft an URL with a sequence of special characters which once interpreted by the server will be equivalent to a forbidden URL. It can be difficult to protect against this attack since the URL can contain other format of encoding such as UTF-8 encoding, Unicode-encoding, etc. The attacker could also subvert the meaning of the URL string request by encoding the data being sent to the server through a GET request. For instance an attacker may subvert the meaning of parameters used in a SQL request and sent through the URL string (See Example section)."], "name": "URL Encoding"}, {"related_weakness": ["180", "181", "173", "171", "172", "73", "21", "22", "74", "20", "697", "707"], "solutions": ["Verify that the user-supplied data does not use backslash character to escape malicious characters.", "Assume all input is malicious. Create a white list that defines all valid input to the software system based on the requirements specifications. Input that does not match against the white list should not be permitted to enter into the system.", "Be aware of the threat of alternative method of data encoding.", "Regular expressions can be used to filter out backslash. Make sure you decode before filtering and validating the untrusted input data.", "In the case of path traversals, use the principle of least privilege when determining access rights to file systems. Do not allow users to access directories/files that they should not access.", "Any security checks should occur after the data has been decoded and validated as correct data format. Do not repeat decoding process, if bad character are left after decoding process, treat the data as suspicious, and fail the validation process.", "Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names."], "id": "78", "prerequisites": ["The application accepts the backlash character as escape character.", "The application server does incomplete input data decoding, filtering and validation."], "summary": ["This attack targets the use of the backslash in alternate encoding. An attacker can provide a backslash as a leading character and causes a parser to believe that the next character is special. This is called an escape. By using that trick, the attacker tries to exploit alternate ways to encode the same character which leads to filter problems and opens avenues to attack."], "name": "Using Escaped Slashes in Alternate Encoding"}, {"related_weakness": ["173", "172", "180", "181", "171", "73", "21", "74", "20", "697", "692"], "solutions": ["The Unicode Consortium recognized multiple representations to be a problem and has revised the Unicode Standard to make multiple representations of the same code point with UTF-8 illegal. The UTF-8 Corrigendum lists the newly restricted UTF-8 range (See references). Many current applications may not have been revised to follow this rule. Verify that your application conform to the latest UTF-8 encoding specification. Pay extra attention to the filtering of illegal characters.", "Another consideration is error recovery. To guarantee correct recovery after corrupt or lost bytes, decoders must be able to recognize the difference between lead and trail bytes, rather than just assuming that bytes will be of the type allowed in their position.", "For security reasons, a UTF-8 decoder must not accept UTF-8 sequences that are longer than necessary to encode a character. If you use a parser to decode the UTF-8 encoding, make sure that parser filter the invalid UTF-8 characters (invalid forms or overlong forms).", "Look for overlong UTF-8 sequences starting with malicious pattern. You can also use a UTF-8 decoder stress test to test your UTF-8 parser (See Markus Kuhn's UTF-8 and Unicode FAQ in reference section)", "Assume all input is malicious. Create a white list that defines all valid input to the software system based on the requirements specifications. Input that does not match against the white list should not be permitted to enter into the system. Test your decoding process against malicious input."], "id": "80", "prerequisites": ["The application's UTF-8 decoder accepts and interprets illegal UTF-8 characters or non-shortest format of UTF-8 encoding.", "Input filtering and validating is not done properly leaving the door open to harmful characters for the target host."], "summary": ["This attack is a specific variation on leveraging alternate encodings to bypass validation logic. This attack leverages the possibility to encode potentially harmful input in UTF-8 and submit it to applications not expecting or effective at validating this encoding standard making input filtering difficult. UTF-8 (8-bit UCS/Unicode Transformation Format) is a variable-length character encoding for Unicode. Legal UTF-8 characters are one to four bytes long. However, early version of the UTF-8 specification got some entries wrong (in some cases it permitted overlong characters). UTF-8 encoders are supposed to use the \"shortest possible\" encoding, but naive decoders may accept encodings that are longer than necessary. According to the RFC 3629, a particularly subtle form of this attack can be carried out against a parser which performs security-critical validity checks against the UTF-8 encoded form of its input, but interprets certain illegal octet sequences as characters."], "name": "Using UTF-8 Encoding to Bypass Validation Logic"}], "id": "CVE-2016-3829", "Published": "2016-08-05T16:59:19.307-04:00", "map_cve_scip": {"sciplink": "http://www.scip.ch/en/?vuldb.90465", "scipid": "90465"}, "summary": "The ih264d decoder in mediaserver in Android 6.x before 2016-08-01 does not initialize certain structure members, which allows remote attackers to cause a denial of service (device hang or reboot) via a crafted media file, aka internal bug 29023649."}